# 第 7 章：指令微调（Finetuning to Follow Instructions）

- [create-preference-data-ollama.ipynb](create-preference-data-ollama.ipynb)：使用 **LLaMA 3.1** 和 **Ollama** 生成 **偏好微调数据集（Preference Finetuning Dataset）** 的笔记本。  
- [dpo-from-scratch.ipynb](dpo-from-scratch.ipynb)：实现 **直接偏好优化（Direct Preference Optimization, DPO）** 以对 **LLM 进行对齐（Alignment）** 的笔记本。  
