{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlvinScrp/LLMs-from-scratch-CN/blob/main/mini-gpt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f678e62-7bcb-4405-86ae-dce94f494303",
      "metadata": {
        "id": "6f678e62-7bcb-4405-86ae-dce94f494303"
      },
      "source": [
        "# 一个简单的GPT2实现"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ac9b5847-0515-45cd-87b0-46541f6a1f79",
      "metadata": {
        "id": "ac9b5847-0515-45cd-87b0-46541f6a1f79",
        "outputId": "4211cced-8478-40ea-d4cb-1423a6dc5582",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.8.0+cu126\n",
            "tiktoken version: 0.12.0\n"
          ]
        }
      ],
      "source": [
        "# NBVAL_IGNORE_OUTPUT\n",
        "from importlib.metadata import version\n",
        "\n",
        "print(\"torch version:\", version(\"torch\"))\n",
        "print(\"tiktoken version:\", version(\"tiktoken\"))\n",
        "import tiktoken\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f60dc93-281d-447e-941f-aede0c7ff7fc",
      "metadata": {
        "id": "3f60dc93-281d-447e-941f-aede0c7ff7fc"
      },
      "source": [
        "## 数据加载\n",
        "* 文本：the-verdict.txt\n",
        "* gpt2 tokenizer\n",
        "* Dataloader\n",
        "* token_embedding position_embedding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "读取`raw_text`后续使用"
      ],
      "metadata": {
        "id": "UcnakenhO7QV"
      },
      "id": "UcnakenhO7QV"
    },
    {
      "cell_type": "code",
      "source": [
        "import os##导入os库\n",
        "import urllib.request ##导入request库\n",
        "\n",
        "def readText(url,file_path):\n",
        "  if not os.path.exists(file_path):\n",
        "    urllib.request.urlretrieve(url, file_path)\n",
        "  with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "  return text\n",
        "\n",
        "#raw_text 后续使用\n",
        "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
        "file_path=\"the-verdict.txt\"\n",
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "file_path=\"tinyshakespeare_input.txt\"\n",
        "\n",
        "raw_text = readText(url,file_path)\n",
        "print(raw_text[:50])"
      ],
      "metadata": {
        "id": "Ho6_RpbcO1S2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4bbe047-f81d-4a26-fff3-17224041e11b"
      },
      "id": "Ho6_RpbcO1S2",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0ed4b7db-3b47-4fd3-a4a6-5f4ed5dd166e",
      "metadata": {
        "id": "0ed4b7db-3b47-4fd3-a4a6-5f4ed5dd166e"
      },
      "outputs": [],
      "source": [
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []  # 输入ID列表\n",
        "        self.target_ids = []  # 目标ID列表\n",
        "\n",
        "        # 对整个文本进行分词\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={'<|endoftext|>'})\n",
        "\n",
        "        # 使用滑动窗口将文本分割成重叠的最大长度序列\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]  # 输入片段\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]  # 目标片段（右移一个位置）\n",
        "            self.input_ids.append(torch.tensor(input_chunk))  # 将输入片段转换为张量\n",
        "            self.target_ids.append(torch.tensor(target_chunk))  # 将目标片段转换为张量\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)  # 返回数据集的大小\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]  # 获取特定索引的输入和目标\n",
        "\n",
        "def create_dataloader(txt, batch_size=4, max_length=256, stride=128, shuffle=True,drop_last=True, num_workers=0):\n",
        "    # 初始化分词器\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    # 创建数据集\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "    # 创建数据加载器\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle,drop_last=drop_last, num_workers=num_workers)\n",
        "\n",
        "    return dataloader  # 返回数据加载器"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "测试代码"
      ],
      "metadata": {
        "id": "7YUCnT0PVgQt"
      },
      "id": "7YUCnT0PVgQt"
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50257  # 词汇表大小\n",
        "output_dim = 256  # 输出维度\n",
        "max_len = 1024  # 最大序列长度\n",
        "context_length = max_len  # 上下文长度\n",
        "\n",
        "\n",
        "token_embedding_layer = nn.Embedding(vocab_size, output_dim)  # 创建词嵌入层\n",
        "pos_embedding_layer =  nn.Embedding(context_length, output_dim)  # 创建位置嵌入层\n",
        "\n",
        "max_length = 4  # 每个输入片段的最大长度\n",
        "dataloader = create_dataloader(raw_text, batch_size=8, max_length=max_length, stride=max_length)  # 创建数据加载器\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")  # 初始化分词器\n",
        "encoded_text = tokenizer.encode(raw_text)  # 对文本进行编码\n",
        "print(raw_text[:50])\n",
        "print(encoded_text[:8])\n",
        "print(tokenizer.decode(encoded_text[:8]))\n",
        "print('-'*20)\n",
        "for batch in dataloader:\n",
        "    x, y = batch\n",
        "\n",
        "    token_embeddings = token_embedding_layer(x)\n",
        "    pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
        "\n",
        "    input_embeddings = token_embeddings + pos_embeddings\n",
        "\n",
        "    break\n",
        "print(input_embeddings.shape)"
      ],
      "metadata": {
        "id": "5OZSFw4zUmXR",
        "outputId": "9cdaf00a-b569-4a61-f7f0-979ab7d4faa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5OZSFw4zUmXR",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear\n",
            "[5962, 22307, 25, 198, 8421, 356, 5120, 597]\n",
            "First Citizen:\n",
            "Before we proceed any\n",
            "--------------------\n",
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd298bf4-e320-40c1-9084-6526d07e6d5d",
      "metadata": {
        "id": "bd298bf4-e320-40c1-9084-6526d07e6d5d"
      },
      "source": [
        "## 注意力机制"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 以下是之前实现的自注意力机制总结（为简化起见，未展示因果和dropout掩码）：\n",
        "\n",
        "- 这种机制也称为单头注意力：\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch03_compressed/24.webp\" width=\"400px\">\n",
        "\n",
        "- 我们通过堆叠多个单头注意力模块来构建多头注意力模块：\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch03_compressed/25.webp\" width=\"400px\">\n",
        "\n",
        "- 多头注意力的核心思想是使用不同的学习到的线性投影，并行地多次运行注意力机制。这使得模型能够在不同位置同时关注来自不同表示子空间的信息。\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch03_compressed/26.webp\" width=\"400px\">"
      ],
      "metadata": {
        "id": "smAFQJDOGsH3"
      },
      "id": "smAFQJDOGsH3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 带掩码的单头自注意力\n",
        "仅示例，后续不会用到"
      ],
      "metadata": {
        "id": "DJaSEfhbWED0"
      },
      "id": "DJaSEfhbWED0"
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalSelfAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    该类实现了因果自注意力机制（Causal Self Attention），\n",
        "    用于自回归模型（例如GPT模型中的注意力层）。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
        "        \"\"\"\n",
        "        初始化因果自注意力层。\n",
        "\n",
        "        参数：\n",
        "        - d_in: 输入维度\n",
        "        - d_out: 输出维度\n",
        "        - context_length: 上下文长度（即注意力机制能“看到”的最大令牌数）\n",
        "        - dropout: Dropout率\n",
        "        - qkv_bias: 是否为查询、键和值使用偏置（默认为False）\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.d_out = d_out\n",
        "        # 定义查询、键、值的线性变换\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "        # Dropout层\n",
        "        self.dropout = nn.Dropout(dropout)  # 新增的Dropout层\n",
        "\n",
        "        # 注册一个buffer，用于存储因果掩码\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))  # 新增掩码，禁止未来的信息\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        前向传播函数计算因果自注意力输出。\n",
        "\n",
        "        参数：\n",
        "        - x: 输入的张量，形状为 (batch_size, num_tokens, d_in)\n",
        "\n",
        "        返回：\n",
        "        - context_vec: 自注意力机制的输出，形状为 (batch_size, num_tokens, d_out)\n",
        "        \"\"\"\n",
        "        b, n_tokens, d_in = x.shape  # 获取输入张量的维度\n",
        "        keys = self.W_key(x)  # 键（K）\n",
        "        queries = self.W_query(x)  # 查询（Q）\n",
        "        values = self.W_value(x)  # 值（V）\n",
        "\n",
        "        # 计算注意力分数（查询和键的点积）\n",
        "        attn_scores = queries @ keys.transpose(1, 2)  # 这里的转置（transpose）是为了匹配维度\n",
        "\n",
        "        # 使用掩码阻止未来的tokens看到当前token\n",
        "        attn_scores.masked_fill_(  # 这里的操作是原地修改\n",
        "            self.mask.bool()[:n_tokens, :n_tokens], -torch.inf)  # 将掩码区域填充为负无穷\n",
        "\n",
        "        # 计算注意力权重并进行softmax归一化\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)  # 使用Dropout层\n",
        "\n",
        "        # 计算上下文向量（加权和）\n",
        "        context_vec = attn_weights @ values\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "sl31Nc92QBkQ"
      },
      "id": "sl31Nc92QBkQ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask =torch.triu(torch.ones(4,4),diagonal=1)\n",
        "# print(mask)\n",
        "q=(torch.arange(1,25)*0.1).reshape(2,4,3).float() # Cast to float\n",
        "k=(torch.arange(1,25)*0.1).reshape(2,4,3).float() # Cast to float\n",
        "print(q)\n",
        "score = q@k.transpose(1,2)\n",
        "print(score)\n",
        "print(torch.bmm(q,k.transpose(1,2)))\n",
        "print(mask.bool())\n",
        "score_masked =score.masked_fill_(mask.bool()[:4,:4],-torch.inf)\n",
        "print(score_masked)\n",
        "score_masked_softmax = torch.softmax(score_masked,dim=-1)\n",
        "print(score_masked_softmax)"
      ],
      "metadata": {
        "id": "dnb96K6XP7Jg",
        "outputId": "adc4d235-ca59-4440-db0a-f85d0f08be1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dnb96K6XP7Jg",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.1000, 0.2000, 0.3000],\n",
            "         [0.4000, 0.5000, 0.6000],\n",
            "         [0.7000, 0.8000, 0.9000],\n",
            "         [1.0000, 1.1000, 1.2000]],\n",
            "\n",
            "        [[1.3000, 1.4000, 1.5000],\n",
            "         [1.6000, 1.7000, 1.8000],\n",
            "         [1.9000, 2.0000, 2.1000],\n",
            "         [2.2000, 2.3000, 2.4000]]])\n",
            "tensor([[[ 0.1400,  0.3200,  0.5000,  0.6800],\n",
            "         [ 0.3200,  0.7700,  1.2200,  1.6700],\n",
            "         [ 0.5000,  1.2200,  1.9400,  2.6600],\n",
            "         [ 0.6800,  1.6700,  2.6600,  3.6500]],\n",
            "\n",
            "        [[ 5.9000,  7.1600,  8.4200,  9.6800],\n",
            "         [ 7.1600,  8.6900, 10.2200, 11.7500],\n",
            "         [ 8.4200, 10.2200, 12.0200, 13.8200],\n",
            "         [ 9.6800, 11.7500, 13.8200, 15.8900]]])\n",
            "tensor([[[ 0.1400,  0.3200,  0.5000,  0.6800],\n",
            "         [ 0.3200,  0.7700,  1.2200,  1.6700],\n",
            "         [ 0.5000,  1.2200,  1.9400,  2.6600],\n",
            "         [ 0.6800,  1.6700,  2.6600,  3.6500]],\n",
            "\n",
            "        [[ 5.9000,  7.1600,  8.4200,  9.6800],\n",
            "         [ 7.1600,  8.6900, 10.2200, 11.7500],\n",
            "         [ 8.4200, 10.2200, 12.0200, 13.8200],\n",
            "         [ 9.6800, 11.7500, 13.8200, 15.8900]]])\n",
            "tensor([[False,  True,  True,  True],\n",
            "        [False, False,  True,  True],\n",
            "        [False, False, False,  True],\n",
            "        [False, False, False, False]])\n",
            "tensor([[[ 0.1400,    -inf,    -inf,    -inf],\n",
            "         [ 0.3200,  0.7700,    -inf,    -inf],\n",
            "         [ 0.5000,  1.2200,  1.9400,    -inf],\n",
            "         [ 0.6800,  1.6700,  2.6600,  3.6500]],\n",
            "\n",
            "        [[ 5.9000,    -inf,    -inf,    -inf],\n",
            "         [ 7.1600,  8.6900,    -inf,    -inf],\n",
            "         [ 8.4200, 10.2200, 12.0200,    -inf],\n",
            "         [ 9.6800, 11.7500, 13.8200, 15.8900]]])\n",
            "tensor([[[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.3894, 0.6106, 0.0000, 0.0000],\n",
            "         [0.1375, 0.2824, 0.5802, 0.0000],\n",
            "         [0.0329, 0.0885, 0.2380, 0.6406]],\n",
            "\n",
            "        [[1.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1780, 0.8220, 0.0000, 0.0000],\n",
            "         [0.0229, 0.1386, 0.8385, 0.0000],\n",
            "         [0.0018, 0.0139, 0.1103, 0.8740]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 多头注意力\n",
        "实际是合并多头权重，做矩阵运算。  而不是分别遍历单头计算，再合并"
      ],
      "metadata": {
        "id": "2serlN1WWItx"
      },
      "id": "2serlN1WWItx"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2773c09d-c136-4372-a2be-04b58d292842",
      "metadata": {
        "id": "2773c09d-c136-4372-a2be-04b58d292842"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    该类实现了多头自注意力机制（Multi-Head Attention），\n",
        "    用于自回归模型（如Transformer和GPT中的注意力层）。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_in, d_out, context_length, dropout,num_heads, qkv_bias=False):\n",
        "        \"\"\"\n",
        "        初始化多头自注意力层。\n",
        "\n",
        "        参数：\n",
        "        - d_in: 输入维度\n",
        "        - d_out: 输出维度\n",
        "        - context_length: 上下文长度（即注意力机制能“看到”的最大令牌数）\n",
        "        - dropout: Dropout率\n",
        "        - num_heads: 注意力头的数量\n",
        "        - qkv_bias: 是否为查询、键和值使用偏置（默认为False）\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # print(f'd_out:{d_out} ,num_heads :{num_heads}')\n",
        "        # 检查输出维度是否能被头数整除\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads  # 将输出维度除以头数，得到每个头的维度\n",
        "\n",
        "        # 定义查询、键、值的线性变换\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "        # 定义输出的线性变换层，用于合并多个头的输出\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # 注册一个buffer，用于存储因果掩码\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))  # 新增掩码，禁止未来的信息\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        前向传播函数，计算多头自注意力输出。\n",
        "\n",
        "        参数：\n",
        "        - x: 输入张量，形状为 (batch_size, num_tokens, d_in)\n",
        "\n",
        "        返回：\n",
        "        - context_vec: 多头自注意力的输出，形状为 (batch_size, num_tokens, d_out)\n",
        "        \"\"\"\n",
        "        b, num_tokens, d_in = x.shape  # 获取输入张量的维度\n",
        "\n",
        "        # 计算键、查询和值的表示\n",
        "        keys = self.W_key(x)  # 键（K）\n",
        "        queries = self.W_query(x)  # 查询（Q）\n",
        "        values = self.W_value(x)  # 值（V）\n",
        "\n",
        "        # 将最后的维度按头数进行拆分：\n",
        "        # 将 (b, num_tokens, d_out) 转换为 (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # 转置以适配矩阵相乘：\n",
        "        # (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # 计算缩放点积注意力（self-attention）\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # 点积计算每个头的注意力分数\n",
        "\n",
        "        # 通过掩码将未来的信息遮掩（变成负无穷）\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]  # 将掩码转换为布尔类型\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)  # 使用掩码将未来的信息填充为负无穷\n",
        "\n",
        "        # 计算注意力权重并进行softmax归一化\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)  # 使用Dropout层\n",
        "\n",
        "        # 计算上下文向量（加权和）\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)  # 恢复维度 (b, num_tokens, num_heads, head_dim)\n",
        "\n",
        "        # 合并头部的输出，并进行线性变换\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)  # 合并头的输出\n",
        "        context_vec = self.out_proj(context_vec)  # 可选的投影层\n",
        "\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "779fdd04-0152-4308-af08-840800a7f395",
      "metadata": {
        "id": "779fdd04-0152-4308-af08-840800a7f395",
        "outputId": "fcaac261-2ef0-447b-b032-10e25bcd252c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context_vecs.shape: torch.Size([8, 4, 256])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "context_length = max_length\n",
        "d_in = output_dim\n",
        "d_out = d_in\n",
        "\n",
        "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
        "\n",
        "batch = input_embeddings\n",
        "context_vecs = mha(batch)\n",
        "\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 模型结构简述"
      ],
      "metadata": {
        "id": "r2-MUZcasOlG"
      },
      "id": "r2-MUZcasOlG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT-2使用的解码器与GPT-1有所不同。\n",
        "\n",
        "GPT-2采用了所谓的预归一化方法，而GPT-1使用的是后归一化。预归一化的核心思想是在主体操作（即多头注意力机制和前馈网络模块）执行之前进行层归一化处理。\n",
        "\n",
        "\n",
        "这种结构被称为 **Pre-LN (Pre-Layer Normalization)**。它与原始 Transformer 论文中将 LayerNorm 放在**之后**的 **Post-LN** 结构不同，优点在于：\n",
        "\n",
        "  * **训练更稳定**: 在 Post-LN 结构中，梯度在反向传播时需要先穿过 LayerNorm，这可能导致梯度在深层网络中爆炸或消失。而在 Pre-LN 中，梯度可以直接通过残差连接的加法操作（梯度为1）无损地向前传播，使得整个网络的梯度流更加稳定，从而可以训练更深的模型。\n",
        "  * **输出更规范**: Pre-LN 保证了输入到注意力层和 FFN 的数据始终是归一化后的，降低了对参数初始化的敏感度。\n",
        "\n",
        "<img src=\"https://towardsdatascience.com/wp-content/uploads/2025/01/16GS2P6dpoWjMQkjDTN0cmA.png\" width=\"500px\">\n",
        "\n"
      ],
      "metadata": {
        "id": "x8loZwoQtiPb"
      },
      "id": "x8loZwoQtiPb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "架构参数"
      ],
      "metadata": {
        "id": "GJMDFVcBtfgr"
      },
      "id": "GJMDFVcBtfgr"
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 1024, # Context length\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False       # Query-Key-Value bias\n",
        "}\n",
        "#初始化定义需要的各种超参数"
      ],
      "metadata": {
        "id": "GvbRZM51sNkd"
      },
      "id": "GvbRZM51sNkd",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add & Layer norm\n",
        "- 残差连接：x + Sublayer(x)\n",
        "- 层归一化：LayerNorm(x + Sublayer(x))"
      ],
      "metadata": {
        "id": "dcHPUbXDuKOi"
      },
      "id": "dcHPUbXDuKOi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Residual Connections 残差连接\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/ba/ResBlock.png/1200px-ResBlock.png\" width=\"400px\">"
      ],
      "metadata": {
        "id": "J3b2urojQpQi"
      },
      "id": "J3b2urojQpQi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LayerNorm 层归一化\n",
        "层归一化是对每个序列中的每一个 Token 单独进行归一化，归一化的计算完全在 Token 内部的特征维度上进行。\n",
        "\n",
        "LayerNorm 的计算逻辑非常简洁：\n",
        "\n",
        "$$\n",
        "y = \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\cdot \\gamma + \\beta\n",
        "$$\n",
        "\n",
        "其中：\n",
        "\n",
        "| 符号            | 含义                 |\n",
        "| ------------- | --------------------- |\n",
        "| x             | 输入特征向量             |\n",
        "| mu (μ)        | 特征维度上的均值           |\n",
        "| sigma\\^2 (σ²) | 特征维度上的方差           |\n",
        "| eps (ε)       | 防止除零的数值稳定项（如 1e-5） |\n",
        "| gamma (γ)     | 可学习的缩放参数（scale）    |\n",
        "| beta (β)      | 可学习的偏移参数（shift）    |"
      ],
      "metadata": {
        "id": "2YxASKA61sDi"
      },
      "id": "2YxASKA61sDi"
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    #layer归一化的函数,可以避免信息泄露也可以稳定\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5 #避免0的产生导致崩溃\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim)) #动态的缩放参数\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim)) #动态的偏移参数\n",
        "\n",
        "    def forward(self, x):\n",
        "        #设置 dim=-1 的意思是让计算沿着最后一个维度进行（在这里是特征维度），而不是按序列处理。\n",
        "        mean = x.mean(dim=-1, keepdim=True)#算平均值\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)#算方差\n",
        "        #通过减去均值并除以方差的平方根（即标准差），可以让输入在列（特征）维度上的均值变为 0，方差变为 1\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)#归一化\n",
        "        #γ 与 β 允许模型学习自适应的缩放与偏移，从而保留归一化前的表达能力。\n",
        "        #在某些场景下，它们甚至可以「撤销」归一化带来的影响，让网络拥有更大的自由度。\n",
        "        return self.scale * norm_x + self.shift"
      ],
      "metadata": {
        "id": "4lbNCzDkvVXF"
      },
      "id": "4lbNCzDkvVXF",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_printoptions(precision=8, sci_mode=False)\n",
        "torch.manual_seed(123)\n",
        "x=torch.randn(1,2,3)\n",
        "print(x)\n",
        "mean = x.mean(dim=-1, keepdim=True)\n",
        "var = x.var(dim=-1, keepdim=True)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)\n",
        "\n",
        "out_norm = (x - mean) / torch.sqrt(var)\n",
        "#执行归一化操作\n",
        "print(\"Normalized layer outputs:\\n\", out_norm)\n",
        "\n",
        "mean = out_norm.mean(dim=-1, keepdim=True)\n",
        "var = out_norm.var(dim=-1, keepdim=True)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)\n",
        "\n",
        "print(\"*\"*10)\n",
        "ln = LayerNorm(emb_dim=3)#归一化一个五维度\n",
        "out_ln = ln(x)\n",
        "mean = out_ln.mean(dim=-1, keepdim=True)\n",
        "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
        "\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM7bPanZ0wiG",
        "outputId": "5d964f6c-fc7f-4915-fe8a-9eaef34061e1"
      },
      "id": "KM7bPanZ0wiG",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.11146712,  0.12036294, -0.36963451],\n",
            "         [-0.24041797, -1.19692433,  0.20926936]]])\n",
            "Mean:\n",
            " tensor([[[-0.12024623],\n",
            "         [-0.40935764]]])\n",
            "Variance:\n",
            " tensor([[[0.06008218],\n",
            "         [0.51575065]]])\n",
            "Normalized layer outputs:\n",
            " tensor([[[ 0.03581607,  0.98161083, -1.01742685],\n",
            "         [ 0.23524030, -1.09664845,  0.86140817]]])\n",
            "Mean:\n",
            " tensor([[[0.],\n",
            "         [0.]]])\n",
            "Variance:\n",
            " tensor([[[1.00000000],\n",
            "         [0.99999994]]])\n",
            "**********\n",
            "Mean:\n",
            " tensor([[[    0.00000000],\n",
            "         [    0.00000004]]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[[0.99975038],\n",
            "         [0.99997091]]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GELU激活函数\n",
        "- 在深度学习中，ReLU（线性整流单元）激活函数因其简单性和在各种神经网络架构中的高效性而被广泛使用。\n",
        "- 在 LLM 中，除了传统的 ReLU，还使用了其他类型的激活函数。例如 GELU（高斯误差线性单元）\n",
        "- GELU (高斯误差线性单元)是一种先进的平滑激活函数，它不像 ReLU 那样在零点进行“一刀切”式的硬性截断，而是根据输入值的统计概率来决定神经元在多大程度上被激活。\n",
        "- 这种概率性的门控机制使得 GELU 的函数曲线处处平滑可导，并在负值区平滑过渡，这与 ReLU 在零点存在尖锐拐角且完全丢弃负值信息形成了鲜明对比。\n",
        "- 总而言之，GELU 通过这种更“自然”的非线性变换，通常能为 Transformer 等现代模型带来优于 ReLU 的性能和更稳定的训练过程。\n",
        "- **GELU**（[Hendrycks 和 Gimpel, 2016](https://arxiv.org/abs/1606.08415)）可以通过多种方式实现；其精确定义为 $\\text{GELU}(x) = x \\cdot \\Phi(x)$，其中 $\\Phi(x)$ 是标准高斯分布的累积分布函数。\n",
        "- 在实际应用中，通常会使用一种计算成本更低的近似形式：  \n",
        "  $\\text{GELU}(x) \\approx 0.5 \\cdot x \\cdot \\left(1 + \\tanh\\left[\\sqrt{\\frac{2}{\\pi}} \\cdot \\left(x + 0.044715 \\cdot x^3\\right)\\right]\\right)$  \n",
        "  （原始 GPT-2 模型也是使用该近似公式进行训练的）。"
      ],
      "metadata": {
        "id": "ytsT6R09qzWy"
      },
      "id": "ytsT6R09qzWy"
    },
    {
      "cell_type": "code",
      "source": [
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            #这一步把它变得平滑了很多\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))"
      ],
      "metadata": {
        "id": "ENuB4QV4DVvx"
      },
      "id": "ENuB4QV4DVvx",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gelu, relu = GELU(), nn.ReLU()#先把函数给个小名\n",
        "\n",
        "# Some sample data\n",
        "x = torch.linspace(-3, 3, 100) #初定义一个张量\n",
        "y_gelu, y_relu = gelu(x), relu(x) #两种激活函数\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
        "    plt.subplot(1, 2, i)\n",
        "    plt.plot(x, y)\n",
        "    plt.title(f\"{label} activation function\")\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(f\"{label}(x)\")\n",
        "    plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "#一个经典的作图"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "zzr5oqRWDWXm",
        "outputId": "46dcda80-3cc1-403e-e5cf-c212e92a6c50"
      },
      "id": "zzr5oqRWDWXm",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PositionWiseFFN 基于位置的前馈神经网络\n",
        "在原始 Transformer 论文、GPT-1、GPT-2 以及后续绝大多数基于 Transformer 的模型（包括 GPT-3, LLaMA 等）中，前馈网络（Feed-Forward Network, FFN）部分都采用了将输入维度扩大4倍，然后再还原回原始维度的结构。\n",
        "> emb_dim -> 4 * emb_dim -> emb_dim\n",
        "\n",
        "这已经成为了 Transformer 架构中的一个标准设计模式。\n",
        "\n",
        "通过将输入 emb_dim 投影到一个更高维的空间（4 * emb_dim），模型在这个“更宽”的空间里有更多的能力去学习和拟合复杂的函数和模式。激活函数（如 GELU）在这个高维空间中进行操作，可以组合出比在原始低维空间中更丰富的特征。最后，第二个线性层再将这些丰富的信息“压缩”并投影回原始的 emb_dim，以便于后续的残差连接。\n",
        "\n",
        "这个过程可以被直观地理解为一个**“记忆”或“特征提取器”**：\n",
        "\n",
        "- 1.第一个线性层将注意力层的输出投影到一个巨大的“特征库”中。\n",
        "\n",
        "- 2.GELU 激活函数根据输入，“点亮”或“激活”了库中相关的特征。\n",
        "\n",
        "- 3.第二个线性层根据被激活的特征，重新组合成一个有意义的输出。"
      ],
      "metadata": {
        "id": "LXTZAxQuq5Ol"
      },
      "id": "LXTZAxQuq5Ol"
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.linear_1 = nn.Linear(emb_dim, 4 * emb_dim)\n",
        "        self.active = GELU()\n",
        "        # 你要找的是这个层\n",
        "        self.linear_2 = nn.Linear(4 * emb_dim, emb_dim)\n",
        "    #运行一次就线性两次激活一次\n",
        "    def forward(self, x):\n",
        "        return self.linear_2(self.active(self.linear_1(x)))"
      ],
      "metadata": {
        "id": "heb1pH7JHXVg"
      },
      "id": "heb1pH7JHXVg",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT2DecoderBlock\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/13.webp?1\" width=\"600px\">\n"
      ],
      "metadata": {
        "id": "rz6U_s13cwXH"
      },
      "id": "rz6U_s13cwXH"
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "class GPT2DecodeBlock(nn.Module):\n",
        "  def __init__(self,emb_dim,context_length,num_heads,num_layers,dropout_rate,qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.attention = MultiHeadAttention(emb_dim,emb_dim,context_length,dropout_rate,num_heads,qkv_bias)\n",
        "    self.ffn = FeedForward(emb_dim)\n",
        "    self.layerNorm1 = LayerNorm(emb_dim)\n",
        "    self.layerNorm2 = LayerNorm(emb_dim)\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    # 2. 对直接连接到残差路径的层进行权重缩放\n",
        "    #    这里我们假设 attention 模块的输出层叫 out_proj, ffn 的第二个线性层也叫 linear_2\n",
        "    #    这是 GPT-2 实践中常见的做法\n",
        "    if hasattr(self.attention, 'out_proj') and hasattr(self.ffn, 'linear_2'):\n",
        "        # 缩放因子分母中的 2*n_layers 代表整个模型中残差连接的总数\n",
        "        scale_factor = math.sqrt(2 * num_layers)\n",
        "\n",
        "        # 对多头注意力的输出投射层权重进行缩放\n",
        "        # 使用正态分布进行初始化，但标准差要除以缩放因子\n",
        "        torch.nn.init.normal_(self.attention.out_proj.weight, mean=0.0, std=0.02 / scale_factor)\n",
        "\n",
        "        # 对前馈网络的第二个线性层权重进行缩放\n",
        "        torch.nn.init.normal_(self.ffn.linear_2.weight, mean=0.0, std=0.02 / scale_factor)\n",
        "    else:\n",
        "        print(\"Warning: c_proj layer not found in attention or ffn. Residual scaling not applied.\")\n",
        "\n",
        "  def forward(self,x):\n",
        "    # 对注意力模块的快捷连接\n",
        "    sourceX = x\n",
        "    x = self.layerNorm1(x)  # 应用第一归一化层\n",
        "    x = self.attention(x)  # 通过多头注意力模块，形状为 [batch_size, num_tokens, emb_size]\n",
        "    x = self.dropout(x)  # 应用 Dropout\n",
        "    x = sourceX + x   # 将原始输入加回，实现残差连接\n",
        "\n",
        "    # 对前馈网络模块的残差连接\n",
        "    sourceX = x\n",
        "    x = self.layerNorm2(x)  # 应用第二归一化层\n",
        "    x = self.ffn(x)  # 通过前馈神经网络模块\n",
        "    x = self.dropout(x)  # 应用 Dropout\n",
        "    x = sourceX + x   # 将原始输入加回，实现残差连接\n",
        "\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "b2UV4wzIhitL"
      },
      "id": "b2UV4wzIhitL",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GPT2Model\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/15.webp\" width=\"600px\">\n"
      ],
      "metadata": {
        "id": "vK1WjSUMowFD"
      },
      "id": "vK1WjSUMowFD"
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2Model(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "\n",
        "    vocab_size = cfg['vocab_size']\n",
        "    emb_dim = cfg['emb_dim']\n",
        "    context_length = cfg['context_length']\n",
        "    num_heads = cfg['n_heads']\n",
        "    n_layers = cfg['n_layers']\n",
        "    dropout_rate = cfg['drop_rate']\n",
        "    qkv_bias = GPT_CONFIG_124M['qkv_bias']\n",
        "\n",
        "    self.tokenEmb = nn.Embedding(vocab_size,emb_dim)\n",
        "    self.postionEmb = nn.Embedding(context_length,emb_dim)\n",
        "    self.embDrop = nn.Dropout(dropout_rate)\n",
        "    self.decodeBlock = nn.Sequential(\n",
        "        *[GPT2DecodeBlock(emb_dim,context_length,num_heads,n_layers,dropout_rate,qkv_bias) for _ in range(n_layers)]\n",
        "    )\n",
        "    self.finalLayerNorm = LayerNorm(emb_dim)\n",
        "    self.outputLinear = nn.Linear(emb_dim,vocab_size)\n",
        "\n",
        "  def forward(self,in_idx):\n",
        "    # print(f'forward:{in_idx.shape}')\n",
        "    batch_size,seq_len, = in_idx.shape\n",
        "    t = self.tokenEmb(in_idx)\n",
        "    # print(f't:{t}')\n",
        "\n",
        "    p = self.postionEmb(torch.arange(seq_len,device=in_idx.device))\n",
        "    # print(f'p:{p}')\n",
        "    x = t + p\n",
        "    x = self.embDrop(x)\n",
        "    x = self.decodeBlock(x)\n",
        "    x = self.finalLayerNorm(x)\n",
        "    logits = self.outputLinear(x)\n",
        "    return logits\n",
        "\n"
      ],
      "metadata": {
        "id": "dxTqt6n1ozeS"
      },
      "id": "dxTqt6n1ozeS",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "#召唤gpt大神\n",
        "batch = []\n",
        "\n",
        "txt1 = \"Every effort moves you\"\n",
        "txt2 = \"Every day holds a\"\n",
        "\n",
        "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
        "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
        "#编码输入文本\n",
        "batch = torch.stack(batch, dim=0)\n",
        "#按照横向来叠加两个向量\n",
        "print(batch)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPT2Model(GPT_CONFIG_124M)\n",
        "\n",
        "out = model(batch)\n",
        "print(\"Input batch:\\n\", batch.shape)\n",
        "print(\"\\nOutput shape:\", out.shape)\n",
        "print(out)\n",
        "#经典操作"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36g319lwNjrK",
        "outputId": "934f9947-3fcf-4cf7-e4ee-645657d1fe79"
      },
      "id": "36g319lwNjrK",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6109, 3626, 6100,  345],\n",
            "        [6109, 1110, 6622,  257]])\n",
            "Input batch:\n",
            " torch.Size([2, 4])\n",
            "\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "tensor([[[-0.67021072, -0.11701202,  0.66688609,  ..., -0.26471528,\n",
            "          -0.12174553,  0.41084272],\n",
            "         [ 1.06572163,  0.10397913, -0.78689599,  ..., -0.00584517,\n",
            "          -0.32707059, -0.43906075],\n",
            "         [ 1.22527230, -0.06391940,  0.00197700,  ...,  0.23192315,\n",
            "           0.23940712, -0.43113047],\n",
            "         [ 0.09830917, -1.87013948, -0.17989337,  ...,  0.56980181,\n",
            "           1.67695785,  0.08691657]],\n",
            "\n",
            "        [[-1.04739201, -0.29219455,  0.68777657,  ...,  0.10014866,\n",
            "          -0.27383161,  0.24262302],\n",
            "         [-0.27236503,  0.13881294, -0.58485043,  ..., -0.24671817,\n",
            "          -0.06416282, -0.26006654],\n",
            "         [-0.03176545,  0.28174189, -0.27445188,  ..., -0.12406659,\n",
            "          -0.14826363, -0.74223864],\n",
            "         [-0.48546624, -0.78222084, -0.06669599,  ..., -0.21058434,\n",
            "           1.29266810, -0.60820180]]], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 其他"
      ],
      "metadata": {
        "id": "-Lh5KW3sbDtn"
      },
      "id": "-Lh5KW3sbDtn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 模型容量\n",
        "原始 GPT-2 论文中，研究人员采用了权重共享（weight tying）技术，即将标记嵌入层（tok_emb）作为输出层复用，具体表现为设置 self.outputLinear.weight = self.tokenEmb.weight。"
      ],
      "metadata": {
        "id": "Toei8lr3XdTg"
      },
      "id": "Toei8lr3XdTg"
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "#模型的总参数数量\n",
        "print(f\"Total number of parameters: {total_params:,}\")\n",
        "\n",
        "#Parameter- sharing\n",
        "total_params_gpt2 =  total_params - sum(p.numel() for p in model.outputLinear.parameters())\n",
        "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")\n",
        "\n",
        "\n",
        "# Calculate the total size in bytes (assuming float32, 4 bytes per parameter)\n",
        "total_size_bytes = total_params * 4\n",
        "\n",
        "# Convert to megabytes\n",
        "total_size_mb = total_size_bytes / (1024 * 1024)\n",
        "\n",
        "#计算总的容量\n",
        "print(f\"Total size of the model: {total_size_mb:.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Gx1d0GkXDDA",
        "outputId": "c9bc09ed-1737-4f6e-8e20-92156613653a"
      },
      "id": "5Gx1d0GkXDDA",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 163,059,793\n",
            "Number of trainable parameters considering weight tying: 124,412,160\n",
            "Total size of the model: 622.02 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  初步测试文本生成\n",
        "-  `generate_text_simple` 实现了一个迭代过程，其中它一次生成一个token。\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch04_compressed/18.webp\" width=\"600px\">"
      ],
      "metadata": {
        "id": "4KGpSZJHaUVQ"
      },
      "id": "4KGpSZJHaUVQ"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx 是当前上下文中的（batch, n_tokens）索引数组\n",
        "    for _ in range(max_new_tokens):\n",
        "        # 每次生成一个单词后，重新将其加入序列中\n",
        "        # idx_cond的序列长度不能超过context_size，否则截取后context_size个\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        # 只关注最后一个时间步的输出\n",
        "        # (batch, n_tokens, vocab_size) 变为 (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "        # 将采样的索引添加到序列中\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "# I HAD always thought Jack Gisburn rather a cheap genius\n",
        "start_context = \"I HAD always thought\"\n",
        "#模拟\n",
        "encoded = tokenizer.encode(start_context)\n",
        "print(\"encoded:\", encoded)\n",
        "#进行语义理解\n",
        "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "print(\"encoded_tensor.shape:\", encoded_tensor.shape)\n",
        "#最终输出格式\n",
        "\n",
        "model.eval() # disable dropout\n",
        "#在检验的时候不需要正则化了\n",
        "out = generate_text_simple(\n",
        "    model=model,\n",
        "    #左边的参数名字,右边是函数传入的实际模型\n",
        "    idx=encoded_tensor, #上下文的索引\n",
        "    max_new_tokens=6, #最多运行六次,然后取结果概率最高的\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output:\", out)\n",
        "print(\"Output length:\", len(out[0]))\n",
        "#输出长度还有每个单词的id\n",
        "\n",
        "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
        "print(decoded_text)\n",
        "\n",
        "\n",
        "import tiktoken\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "#举个例子\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context, tokenizer),\n",
        "    #初始上下文的Token ID张量，是上一步 text_to_token_ids 的输出\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "#输出最长单词度为10的句子\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXIgaSs8aXdR",
        "outputId": "64ab9c50-46b6-469a-f364-1924f929a871"
      },
      "id": "wXIgaSs8aXdR",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded: [40, 367, 2885, 1464, 1807]\n",
            "encoded_tensor.shape: torch.Size([1, 5])\n",
            "Output: tensor([[   40,   367,  2885,  1464,  1807, 42581,  3544, 38205,  4761,   319,\n",
            "         32628]])\n",
            "Output length: 11\n",
            "I HAD always thoughtudence uses69672 on mantra\n",
            "Output text:\n",
            " Every effort moves you Constantfunctional combines laurebara Rolling Admiral soarideshow shading\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 自监督预训练"
      ],
      "metadata": {
        "id": "Ll29AyPreOLQ"
      },
      "id": "Ll29AyPreOLQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 交叉熵损失(cross-entropy-loss)和困惑度(perplexity)\n",
        "实现交叉熵损失（Cross-Entropy Loss）可以从两个层面来理解：一是自己动手从零实现以理解其原理，二是直接使用 PyTorch、TensorFlow 等深度学习框架中已经优化好的函数。"
      ],
      "metadata": {
        "id": "A7WirecahxDQ"
      },
      "id": "A7WirecahxDQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. softmax\n",
        "Softmax函数是一个将一组实数转换为概率分布的数学公式。\n",
        "\n",
        "在机器学习中，它主要用于将模型输出的原始分数（称为**logits**）转换为多类别分类问题中的概率。转换后，所有类别的概率总和为1，这使得模型的输出易于理解。\n",
        "\n",
        "对于向量 $z$ 中的分数 $z_i$，其公式为：\n",
        "\n",
        "$$\\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}$$\n",
        "\n",
        "其中：\n",
        "* $z_i$ 是第 $i$ 个类别的输入分数。\n",
        "* $e^{z_i}$ 是应用于该分数的标准指数函数，它使所有输出都为正数。\n",
        "* $\\sum_{j=1}^{K} e^{z_j}$ 是所有分数指数的总和，作为归一化因子。"
      ],
      "metadata": {
        "id": "xj_S8jraGmnk"
      },
      "id": "xj_S8jraGmnk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 核心概念与原理\n",
        "\n",
        "交叉熵损失是分类问题中最常用的损失函数。它的核心思想是**衡量模型预测的概率分布与真实的标签概率分布之间的差异**。\n",
        "\n",
        "  * **真实分布 (True Distribution)**：在分类问题中，一个样本只属于一个类别。我们通常用独热编码（One-Hot Encoding）来表示，例如对于一个三分类问题，标签为 \"类别1\" 的真实分布就是 `[1, 0, 0]`。\n",
        "  * **预测分布 (Predicted Distribution)**：这是模型经过 Softmax 函数后输出的，表示模型认为样本属于每个类别的概率，例如 `[0.7, 0.2, 0.1]`。\n",
        "\n",
        "交叉熵损失值越小，说明模型的预测分布越接近真实分布，模型性能越好。\n"
      ],
      "metadata": {
        "id": "raNVVLznIh1u"
      },
      "id": "raNVVLznIh1u"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 数学公式\n",
        "\n",
        "对于单个样本，交叉熵损失的计算公式如下：\n",
        "\n",
        "$$L = - \\sum_{i=1}^{C} y_i \\log(\\hat{y}_i)$$\n",
        "\n",
        "其中：\n",
        "\n",
        "  * $C$ 是类别的总数。\n",
        "  * $y_i$ 是真实分布的第 $i$ 个元素（对于 One-Hot 编码，如果真实类别是 $i$，则 $y_i=1$，否则 $y_i=0$）。\n",
        "  * $\\hat{y}_i$ 是模型预测样本属于类别 $i$ 的概率。\n",
        "\n",
        "#### **公式简化**\n",
        "\n",
        "因为 $y$ 是 One-Hot 向量，只有一个位置是 1（假设为类别 $k$），其他位置都是 0。所以上面那个求和公式可以大大简化：\n",
        "\n",
        "$$L = - (0 \\cdot \\log(\\hat{y}_1) + \\dots + 1 \\cdot \\log(\\hat{y}_k) + \\dots + 0 \\cdot \\log(\\hat{y}_C)) = -\\log(\\hat{y}_k)$$\n",
        "\n",
        "**简化后的直观理解**：单个样本的损失，就是**模型预测的正确类别的概率的负对数**。\n",
        "\n",
        "  * 如果模型对正确类别 $k$ 的预测概率 $\\hat{y}_k$ 很高（如 0.99），那么 $-\\log(0.99)$ 是一个很小的数，损失很小。\n",
        "  * 如果模型对正确类别 $k$ 的预测概率 $\\hat{y}_k$ 很低（如 0.01），那么 $-\\log(0.01)$ 是一个很大的数，损失很大。这会驱动模型更新参数，提高正确类别的预测概率。"
      ],
      "metadata": {
        "id": "Q2IZRPk0IkGz"
      },
      "id": "Q2IZRPk0IkGz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 从零开始实现 (使用 NumPy)\n",
        "\n",
        "为了真正理解其工作原理，我们可以用 NumPy 来手动实现。这通常包括两步：Softmax 函数和交叉熵计算。"
      ],
      "metadata": {
        "id": "QEi7gNVbImnt"
      },
      "id": "QEi7gNVbImnt"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def softmax(logits):\n",
        "    \"\"\"\n",
        "    计算 softmax 函数\n",
        "    Args:\n",
        "        logits: 模型的原始输出，形状为 (batch_size, num_classes)\n",
        "    Returns:\n",
        "        probs: 概率分布，形状和 logits 相同\n",
        "    \"\"\"\n",
        "    # 为了数值稳定性，减去最大值防止 exp 溢出\n",
        "    exp_logits = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
        "    return exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
        "\n",
        "def cross_entropy_loss_manual(logits, y_true):\n",
        "    \"\"\"\n",
        "    手动实现交叉熵损失\n",
        "    Args:\n",
        "        logits: 模型的原始输出 (batch_size, num_classes)\n",
        "        y_true: 真实的标签，整数索引 (batch_size,)\n",
        "    Returns:\n",
        "        loss: 批次的平均损失\n",
        "    \"\"\"\n",
        "    batch_size = logits.shape[0]\n",
        "\n",
        "    # 1. 计算概率\n",
        "    probs = softmax(logits)\n",
        "\n",
        "    # 2. 提取正确类别的预测概率\n",
        "    # 使用高级索引，从 probs 的每一行中，根据 y_true 中指定的列索引提取概率值\n",
        "    correct_class_probs = probs[np.arange(batch_size), y_true]\n",
        "\n",
        "    # 3. 计算负对数损失\n",
        "    # 添加一个很小的数 epsilon 防止 log(0) 导致 -inf\n",
        "    epsilon = 1e-9\n",
        "    log_probs = -np.log(correct_class_probs + epsilon)\n",
        "\n",
        "    # 4. 计算批次的平均损失\n",
        "    loss = np.mean(log_probs)\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "8ynMcmBoG4tT"
      },
      "id": "8ynMcmBoG4tT",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 4. 使用 PyTorch 内置函数 (推荐)\n",
        "\n",
        "在实际应用中，我们**强烈推荐**使用框架内置的函数，因为它们经过了高度优化，并且能自动处理数值稳定性问题。\n",
        "\n",
        "PyTorch 中的 `torch.nn.CrossEntropyLoss` 是一个非常方便的模块, 内部**自动**包含了 `Softmax` 操作。因此，**你只需要将模型的原始输出（logits）直接传入即可**，不需要自己手动调用 Softmax。\n",
        "\n",
        "CrossEntropyLoss 内部实际是通过`Log-Sum-Exp Trick`(nn.LogSoftmax)和 负对数似然损失 (nn.NLLLoss) 实现。\n",
        "\n",
        "你会发现，手动实现的结果和 PyTorch 计算的结果几乎完全一样（可能因浮点数精度有微小差异）。"
      ],
      "metadata": {
        "id": "1OxdDAEmHBWa"
      },
      "id": "1OxdDAEmHBWa"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# --- 示例 ---\n",
        "# 假设批次大小为 2，共 3 个类别\n",
        "# 模型的原始输出（logits），需要是 FloatTensor\n",
        "sample_logits_torch = torch.tensor([\n",
        "    [2.0, 8.0, 0.1],\n",
        "    [0.5, 1.5, 1.5]\n",
        "], dtype=torch.float32)\n",
        "\n",
        "# 真实标签（类别索引），需要是 LongTensor\n",
        "sample_y_true_torch = torch.tensor([0, 2], dtype=torch.long)\n",
        "\n",
        "# PyTorch 默认计算批次的平均损失 (reduction='mean')\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "loss = loss_fn(sample_logits_torch, sample_y_true_torch)\n",
        "print(f\"PyTorch内置的交叉熵损失: {loss.item():.4f}\")\n",
        "\n",
        "\n",
        "lossManual = cross_entropy_loss_manual(sample_logits_torch.numpy(), sample_y_true_torch.numpy())\n",
        "print(f\"手动实现的交叉熵损失: {lossManual:.4f}\")"
      ],
      "metadata": {
        "id": "8VrYTp6EHNhm",
        "outputId": "a429f2f1-f802-421e-d839-d8f75b747518",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8VrYTp6EHNhm",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch内置的交叉熵损失: 3.4324\n",
            "手动实现的交叉熵损失: 3.4324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 困惑度\n",
        "- 与交叉熵损失相关的一个概念是大语言模型的困惑度 (perplexity)。\n",
        "- 困惑度就是交叉熵损失的指数值。\n",
        "- 困惑度通常被认为更易解释，因为它可以理解为模型在每一步对词汇表大小的不确定性，值越大表示可能的token越多。\n",
        "- 换句话说，困惑度提供了一个衡量模型预测的概率分布与数据集中单词实际分布匹配程度的指标。\n",
        "- 类似于损失值，较低的困惑度表示模型预测与实际分布的差距较小。"
      ],
      "metadata": {
        "id": "YORJLDtYJzrH"
      },
      "id": "YORJLDtYJzrH"
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = torch.exp(loss)\n",
        "#指数化loss作为P值\n",
        "print(perplexity)"
      ],
      "metadata": {
        "id": "xmIjm1bGJ4Q5",
        "outputId": "05752395-88cf-4bc3-b8f9-58f5e58a124e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xmIjm1bGJ4Q5",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(30.95145416)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 计算训练集和验证集的损失"
      ],
      "metadata": {
        "id": "002kOjAwOUrE"
      },
      "id": "002kOjAwOUrE"
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,   # Vocabulary size\n",
        "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
        "    \"emb_dim\": 768,        # Embedding dimension\n",
        "    \"n_heads\": 12,         # Number of attention heads\n",
        "    \"n_layers\": 12,        # Number of layers\n",
        "    \"drop_rate\": 0.1,      # Dropout rate\n",
        "    \"qkv_bias\": False      # Query-key-value bias\n",
        "}"
      ],
      "metadata": {
        "id": "vDmrv1-3SR3o"
      },
      "id": "vDmrv1-3SR3o",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 我们在上述代码中使用了 0.1 的 dropout 率，但如今训练大语言模型时通常不使用 dropout。\n",
        "- 现代的大语言模型不在 `nn.Linear` 层的查询、键和值矩阵中使用偏置向量（与早期的 GPT 模型不同），而是通过设置 `\"qkv_bias\": False` 实现。\n",
        "- 我们将上下文长度（`context_length`）减少到仅 256 个 token，以减少训练模型时的计算资源需求，而原始的 1.24 亿参数的 GPT-2 模型使用了 1024 个token。\n",
        "  - 这是为了让更多读者可以在他们的笔记本电脑上运行并跟随代码示例。\n",
        "  - 然而，您可以自由将 `context_length` 增加到 1024 个 token（这不需要更改任何代码）。\n",
        "  - 我们稍后也将从预训练权重中加载一个具有 1024 `context_length` 的模型。"
      ],
      "metadata": {
        "id": "GoK2r2kWSPgg"
      },
      "id": "GoK2r2kWSPgg"
    },
    {
      "cell_type": "code",
      "source": [
        "print(raw_text[:99])\n",
        "print(raw_text[-99:])\n",
        "#统计一下文本的长度,编码文本内容并输出文本个数\n",
        "print(\"Characters:\", len(raw_text))\n",
        "print(\"Tokens:\", len(tokenizer.encode(raw_text)))"
      ],
      "metadata": {
        "id": "38UIiCXSOm-b",
        "outputId": "3df3bfe1-f1c4-43b9-c571-d94ddb8cf8e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "38UIiCXSOm-b",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "Yo\n",
            "ONIO:\n",
            "Noble Sebastian,\n",
            "Thou let'st thy fortune sleep--die, rather; wink'st\n",
            "Whiles thou art waking.\n",
            "\n",
            "Characters: 1115394\n",
            "Tokens: 338025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/validation ratio\n",
        "train_ratio = 0.80\n",
        "split_idx = int(train_ratio * len(raw_text))\n",
        "train_data = raw_text[:split_idx]\n",
        "val_data = raw_text[split_idx:]\n",
        "\n",
        "#依旧保持可复现\n",
        "torch.manual_seed(123)\n",
        "\n",
        "#初始化输入训练模型,给出批处理的大小、给出最大文本容量防止溢出\n",
        "#给出不畅,丢弃最后一批不足的文本,打开随机防止拟合过度\n",
        "train_loader = create_dataloader(\n",
        "    train_data,\n",
        "    batch_size=32,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "#验证数据集仅仅修改了是否丢弃跟随抽取\n",
        "val_loader = create_dataloader(\n",
        "    val_data,\n",
        "    batch_size=32,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n"
      ],
      "metadata": {
        "id": "IYKesjPYP7_3"
      },
      "id": "IYKesjPYP7_3",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_tokens = len(tokenizer.encode(raw_text))\n",
        "print(total_tokens * (train_ratio),total_tokens * (1-train_ratio),GPT_CONFIG_124M[\"context_length\"])\n",
        "# for x, y in train_loader:\n",
        "#     print(x.shape, y.shape)\n",
        "\n",
        "# print(\"\\nValidation loader:\")\n",
        "# for x, y in val_loader:\n",
        "#     print(x.shape, y.shape)"
      ],
      "metadata": {
        "id": "TiN_htfXQbFg",
        "outputId": "3c0d6f18-752a-4f36-c733-363afa86d0c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TiN_htfXQbFg",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270420.0 67604.99999999999 256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, start_context, tokenizer):\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "            logits = model(input_batch)\n",
        "            logits = logits.view(-1, logits.size(-1))\n",
        "            target_batch = target_batch.view(-1)\n",
        "\n",
        "            l = loss(logits, target_batch)\n",
        "            l.backward()\n",
        "            optimizer.step()\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "\n",
        "        train_l = evaluate_model(model,train_loader,loss)\n",
        "        val_l = evaluate_model(model, val_loader,loss)\n",
        "        train_losses.append(train_l)\n",
        "        val_losses.append(val_l)\n",
        "        track_tokens_seen.append(tokens_seen)\n",
        "        end_time = time.time()\n",
        "        execution_time_minutes = (end_time - start_time) / 60\n",
        "        print(f\"耗时 {execution_time_minutes:.2f} 分钟。\")\n",
        "\n",
        "        print(f\"Ep {epoch+1} : \"\n",
        "                      f\"Train loss {train_l:.3f}, Val loss {val_l:.3f}\"\n",
        "                      f\"耗时 {execution_time_minutes:.2f} 分钟。\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample( model, tokenizer, device, start_context)\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "def evaluate_model(model, data_loader,  loss):\n",
        "    \"\"\"\n",
        "    计算给定数据加载器上模型的每个样本的平均损失\n",
        "    \"\"\"\n",
        "    model.eval()  # 将模型设置为评估模式，这会关闭Dropout\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():  # 在评估时不需要计算梯度，可以节省计算资源和内存\n",
        "        for input_batch, target_batch in data_loader:\n",
        "            size = input_batch.size(0)\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "            logits = model(input_batch)\n",
        "            logits = logits.view(-1, logits.size(-1))\n",
        "            target_batch = target_batch.view(-1)\n",
        "\n",
        "            l = loss(logits, target_batch)\n",
        "            total_loss += l.item() * size\n",
        "            total_samples += size\n",
        "\n",
        "    model.train()  # 如果后续还需要训练，记得将模型切换回训练模式\n",
        "\n",
        "    epoch_loss = total_loss / total_samples\n",
        "    return epoch_loss\n",
        "\n",
        "\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.postionEmb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "5sud3Q3HVfzs"
      },
      "id": "5sud3Q3HVfzs",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPT2Model(GPT_CONFIG_124M)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs,\n",
        "    eval_freq=5,\n",
        "    # start_context=\"I have mentioned that Mrs\",\n",
        "    start_context=\"Still cupboarding the viand\",\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"训练完成耗时 {execution_time_minutes:.2f} 分钟。\")\n"
      ],
      "metadata": {
        "id": "XLwI19SfSclf",
        "outputId": "60b08e90-0517-4e7e-df61-2b87142b576b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        }
      },
      "id": "XLwI19SfSclf",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacity of 14.74 GiB of which 638.12 MiB is free. Process 7296 has 14.12 GiB memory in use. Of the allocated memory 13.92 GiB is allocated by PyTorch, and 69.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2465129906.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0004\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m train_losses, val_losses, tokens_seen = train_model_simple(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3417470463.py\u001b[0m in \u001b[0;36mtrain_model_simple\u001b[0;34m(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, start_context, tokenizer)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mtarget_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m         return F.cross_entropy(\n\u001b[0m\u001b[1;32m   1311\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3460\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3461\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3462\u001b[0;31m     return torch._C._nn.cross_entropy_loss(\n\u001b[0m\u001b[1;32m   3463\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3464\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacity of 14.74 GiB of which 638.12 MiB is free. Process 7296 has 14.12 GiB memory in use. Of the allocated memory 13.92 GiB is allocated by PyTorch, and 69.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Still cupboarding the viand, never bearing\n",
        "Like labour with the rest, where the other instruments\n",
        "Did see and hear, devise, instruct, walk, feel,\n",
        "And, mutually participate, did minister\n",
        "Unto the appetite and affection common\n",
        "Of the whole body. The belly answer'd--"
      ],
      "metadata": {
        "id": "7fFhFCtmNjlO"
      },
      "id": "7fFhFCtmNjlO"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
        "#一个经典的plot画图函数"
      ],
      "metadata": {
        "id": "7OxyMkNyIyZv"
      },
      "id": "7OxyMkNyIyZv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " `the-verdict.txt` 文件确实非常小，只有几千个单词，主要用于教学演示，让代码能快速跑通。要训练一个稍微有点样子的模型，你需要大得多的文本。\n",
        "\n",
        "这里为你推荐几个不同量级的文本数据链接，从易到难，你可以根据自己的需求选择。\n",
        "\n",
        "### 1\\. 直接替换的单个 .txt 文件 (中等大小)\n",
        "\n",
        "这是一个最直接的“升级”选择，和 `the-verdict.txt` 一样，是一个单独的 `.txt` 文件，但内容要多得多。\n",
        "\n",
        "**推荐：莎士比亚全集 (The Complete Works of William Shakespeare)**\n",
        "\n",
        "这个文件大约有 1.1MB，包含了莎士比亚所有的戏剧和诗歌。它是 NLP 入门领域非常经典的语料库。\n",
        "\n",
        "  * **链接:**\n",
        "    ```\n",
        "    https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "    ```\n",
        "  * **优点:**\n",
        "      * 比 `the-verdict.txt` 大上百倍。\n",
        "      * 单一 `.txt` 文件，无需处理，可以直接下载使用。\n",
        "      * 文本风格统一，语言经典。\n",
        "  * **缺点:**\n",
        "      * 内容是古英语，和现代英语有差异。"
      ],
      "metadata": {
        "id": "Pi7rOQ2IMzdM"
      },
      "id": "Pi7rOQ2IMzdM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2\\. 需要简单代码处理的数据集 (大)\n",
        "\n",
        "对于更严肃的训练，通常不会用单个 `.txt` 文件，而是使用专门的数据集。Hugging Face 的 `datasets` 库是获取它们的标准方式。你只需要几行代码就可以下载并整合成一个大文本文件。\n",
        "\n",
        "**推荐：TinyStories 数据集**\n",
        "\n",
        "这是一个专门为训练小型语言模型设计的高质量数据集，由 GPT-3.5 和 GPT-4 生成的简短故事组成，内容简单、语法正确、逻辑连贯。\n",
        "\n",
        "  * **优点:**\n",
        "      * 数据量大且质量非常高，非常适合从零开始训练。\n",
        "      * 内容是现代、简单的英语，模型更容易学习。\n",
        "  * **如何使用:**\n",
        "    你需要先安装 `datasets` 库:\n",
        "    ```bash\n",
        "    pip install datasets\n",
        "    ```\n",
        "然后用下面的 Python 脚本来下载并保存为文本文件："
      ],
      "metadata": {
        "id": "UIngMAbrM6PS"
      },
      "id": "UIngMAbrM6PS"
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import os\n",
        "\n",
        "# 下载数据集（会自动缓存）\n",
        "print(\"Downloading TinyStories dataset...\")\n",
        "dataset = load_dataset(\"roneneldan/TinyStories\", split='train')\n",
        "\n",
        "# 定义要保存的文件名\n",
        "output_filename = \"tinystories.txt\"\n",
        "\n",
        "# 设定要处理的数据条数 (可以先用少量数据测试)\n",
        "# 例如，只处理前 10000 个故事\n",
        "num_stories_to_process = 10000\n",
        "\n",
        "print(f\"Processing and writing to {output_filename}...\")\n",
        "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    for i, story in enumerate(dataset):\n",
        "        if i >= num_stories_to_process:\n",
        "            break\n",
        "        f.write(story['text'])\n",
        "        f.write(\"\\n\\n\") # 每个故事之间用两个换行符隔开\n",
        "        if (i + 1) % 1000 == 0:\n",
        "            print(f\"Processed {i+1}/{num_stories_to_process} stories.\")\n",
        "\n",
        "file_size = os.path.getsize(output_filename) / (1024 * 1024)\n",
        "print(f\"Done. File '{output_filename}' created successfully.\")\n",
        "print(f\"File size: {file_size:.2f} MB\")"
      ],
      "metadata": {
        "id": "3s7A7LKkNCWU"
      },
      "id": "3s7A7LKkNCWU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "如果你想处理整个数据集，请移除 num_stories_to_process 的限制\n",
        "注意：完整的数据集非常大，生成的 .txt 文件会达到 GB 级别，请确保磁盘空间充足\n",
        "\n",
        "\n",
        "### 3\\. 更大规模的语料库 (超大)\n",
        "\n",
        "如果你想进一步挑战，可以尝试使用维基百科的数据。\n",
        "\n",
        "**推荐：维基百科英文数据 (Wikipedia)**\n",
        "\n",
        "这是训练大型模型常用的高质量语料库之一。\n",
        "\n",
        "  * **如何使用:**\n",
        "    同样可以使用 `datasets` 库来获取处理好的维基百科数据。\n",
        "    ```python\n",
        "    from datasets import load_dataset\n",
        "\n",
        "    # 下载一个处理好的维基百科数据快照\n",
        "    # 这会下载很大的数据，请确保网络和磁盘空间足够\n",
        "    dataset = load_dataset(\"wikipedia\", \"20220301.en\", split='train')\n",
        "\n",
        "    # 后续处理方式与 TinyStories 类似，将'text'字段写入文件\n",
        "    # 但要注意，这个数据集非常庞大，建议先取一小部分进行操作\n",
        "    ```\n",
        "\n",
        "### 总结与建议\n",
        "\n",
        "  * **新手入门/快速实验:** 直接使用 **莎士比亚全集** 的链接。它是最简单的升级方案。\n",
        "  * **认真学习/训练小模型:** 强烈推荐 **TinyStories 数据集**。它的数据质量和规模都非常适合《LLMs from scratch》这本书的后续学习。\n",
        "  * **进阶挑战:** 当你熟悉了整个流程后，可以尝试使用 **维基百科** 的一部分数据来训练更大的模型。"
      ],
      "metadata": {
        "id": "WWT8Ri_kMuMk"
      },
      "id": "WWT8Ri_kMuMk"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}