# 第三章：编码注意力机制

&nbsp;
## 章节主要代码

- [01_main-chapter-code](01_main-chapter-code) 包含了章节的主要代码。

&nbsp;
## 额外材料

- [02_bonus_efficient-multihead-attention](02_bonus_efficient-multihead-attention) 实现并比较了多头注意力的不同实现变体。

- [03_understanding-buffers](03_understanding-buffers) 解释了 PyTorch 缓冲区的概念，这些缓冲区用于实现第三章中的因果注意力机制。