## **扩展 Tiktoken BPE 分词器以支持新标记**

在本教程中，我们将探讨如何在 `tiktoken` 实现的分词器（Tokenizer）中添加特殊标记（Special Tokens），并相应地更新 LLM（大语言模型）。

- [📜 extend-tiktoken.ipynb](extend-tiktoken.ipynb)  
  该 Jupyter Notebook 文件包含可选（额外）代码，详细说明了如何向 `tiktoken` 分词器添加特殊标记，并调整 LLM 以支持这些标记。