{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4855611",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2Model.from_pretrained('gpt2')\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbbb5a9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1203d226",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# 检查是否有可用的 GPU，并设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用的设备: {device}\")\n",
    "\n",
    "# 1. 加载带有语言模型头的模型和分词器\n",
    "# 将模型移动到指定的设备上\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.to(device)\n",
    "\n",
    "# 2. 准备输入提示\n",
    "# 对于GPT-2这样的模型，提供故事的开头通常比给指令效果更好。\n",
    "# 我们给它一个故事的引子，而不是一个命令。\n",
    "prompt_text = \"In a cozy little cottage, lived a fluffy cat named Whiskers. One sunny morning,\"\n",
    "prompt_text = \"In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\"\n",
    "\n",
    "# 3. 对输入进行编码\n",
    "# 将提示文本转换为模型可以理解的数字ID (tokens)，并将其发送到设备\n",
    "input_ids = tokenizer.encode(prompt_text, return_tensors='pt').to(device)\n",
    "\n",
    "# 4. 使用 model.generate() 生成文本\n",
    "print(\"\\n正在生成故事...\")\n",
    "# 调用 generate 方法来创作故事\n",
    "output_sequences = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=200,          # 生成文本的最大长度（包含提示）\n",
    "    num_return_sequences=1,  # 生成几个不同的故事\n",
    "    no_repeat_ngram_size=2,  # 避免重复短语的关键参数\n",
    "    do_sample=True,          # 启用采样，让文本更有创意，而不是死板的预测\n",
    "    temperature=0.9,         # 控制创造性与确定性的平衡，数值越低越保守\n",
    "    top_k=50,                # 采样时只考虑概率最高的50个词\n",
    "    top_p=0.95,              # 核心采样，保留概率总和为95%的词汇\n",
    ")\n",
    "\n",
    "# 5. 解码生成的文本\n",
    "# 将生成的数字ID序列转换回人类可读的字符串\n",
    "generated_text = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "\n",
    "# 6. 打印结果\n",
    "print(\"\\n--- 生成的故事 ---\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6093a7ed",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
